{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #  A Whale off the Port(folio)\n",
    "\n",
    " In this assignment, you'll get to use what you've learned this week to evaluate the performance among various algorithmic, hedge, and mutual fund portfolios and compare them against the S&P 500."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from pathlib import Path\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "\n",
    "In this section, you will need to read the CSV files into DataFrames and perform any necessary data cleaning steps. After cleaning, combine all DataFrames into a single DataFrame.\n",
    "\n",
    "Files:\n",
    "1. whale_returns.csv\n",
    "2. algo_returns.csv\n",
    "3. sp500_history.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Whale Returns\n",
    "\n",
    "Read the Whale Portfolio daily returns and clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading whale returns, algo & SP500:\n",
    "whale_returns_csv = Path('Resources/whale_returns.csv')\n",
    "\n",
    "# Importing read CSV file into DataFrames:\n",
    "whale_df = pd.read_csv(whale_returns_csv, index_col='Date', infer_datetime_format=True, parse_dates=True)\n",
    "\n",
    "# Sorting dataframe:\n",
    "whale_df.sort_index(inplace=True)\n",
    "whale_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count nulls\n",
    "whale_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop nulls\n",
    "whale_df.dropna(inplace=True)\n",
    "whale_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithmic Daily Returns\n",
    "\n",
    "Read the algorithmic daily returns and clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading algorithmic returns\n",
    "algo_returns_csv = Path(\"Resources/algo_returns.csv\")\n",
    "\n",
    "# importing CSV data into dataframe:\n",
    "algo_df = pd.read_csv(algo_returns_csv, index_col='Date', infer_datetime_format=True, parse_dates=True)\n",
    "\n",
    "# sorting dataframe from oldedst to newest:\n",
    "algo_df.sort_index(inplace=True)\n",
    "algo_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count nulls\n",
    "algo_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop nulls\n",
    "algo_df.dropna(inplace=True)\n",
    "algo_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S&P 500 Returns\n",
    "\n",
    "Read the S&P500 Historic Closing Prices and create a new daily returns DataFrame from the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading S&P 500 Closing Prices\n",
    "sp500_history_csv = Path(\"Resources/sp500_history.csv\")\n",
    "\n",
    "# importing CSV data into dataframe:\n",
    "sp500_df = pd.read_csv(sp500_history_csv, index_col='Date', infer_datetime_format=True, parse_dates=True)\n",
    "\n",
    "# sorting dataframe from oldest to newest:\n",
    "sp500_df.sort_index(inplace=True)\n",
    "sp500_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Data Types\n",
    "sp500_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix Data Types\n",
    "# removing the '$' from all close prices within the 'Close' column and converting to float:\n",
    "sp500_df['Close'] = sp500_df['Close'].str.replace(r'\\$', '').astype(float)\n",
    "sp500_df.dtypes   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Daily Returns\n",
    "sp500_returns_df = sp500_df.pct_change()\n",
    "sp500_returns_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop nulls\n",
    "sp500_returns_df.dropna(inplace=True)\n",
    "sp500_returns_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename Column\n",
    "sp500_returns_df.columns = ['S&P 500']\n",
    "sp500_returns_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine Whale, Algorithmic, and S&P 500 Returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenating all DataFrames into a single DataFrame and sorting the data:\n",
    "combined_df = pd.concat([whale_df, algo_df, sp500_returns_df], axis='columns', join='inner')\n",
    "combined_df.sort_index()\n",
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Portfolio Analysis\n",
    "\n",
    "In this section, you will calculate and visualize performance and risk metrics for the portfolios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance\n",
    "\n",
    "Calculate and Plot the daily returns and cumulative returns. Does any portfolio outperform the S&P 500? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting combined daily returns\n",
    "combined_df.plot(figsize=(20,15),title= \"Historical Returns vs. SP500\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting cumulative returns\n",
    "cumulative_returns = (1+ combined_df).cumprod().plot(figsize=(20,15), title=\"Cumulative Returns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Risk\n",
    "\n",
    "Determine the _risk_ of each portfolio:\n",
    "\n",
    "1. Create a box plot for each portfolio. \n",
    "2. Calculate the standard deviation for all portfolios\n",
    "4. Determine which portfolios are riskier than the S&P 500\n",
    "5. Calculate the Annualized Standard Deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Box plot to visually show risk\n",
    "combined_df.plot(kind='box', figsize=(20,15), title='Portfolio Risk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daily Standard Deviations\n",
    "# Calculate the standard deviation for each portfolio. \n",
    "# Which portfolios are riskier than the S&P 500?\n",
    "combined_df.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine which portfolios are riskier than the S&P 500\n",
    "riskier_df = combined_df.std() > .008554\n",
    "riskier_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the annualized standard deviation (252 trading days)\n",
    "annualized_df = combined_df.std() * np.sqrt(252)\n",
    "annualized_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rolling Statistics\n",
    "\n",
    "Risk changes over time. Analyze the rolling statistics for Risk and Beta. \n",
    "\n",
    "1. Plot the rolling standard deviation of the various portfolios along with the rolling standard deviation of the S&P 500 (consider a 21 day window). Does the risk increase for each of the portfolios at the same time risk increases in the S&P?\n",
    "2. Construct a correlation table for the algorithmic, whale, and S&P 500 returns. Which returns most closely mimic the S&P?\n",
    "3. Choose one portfolio and plot a rolling beta between that portfolio's returns and S&P 500 returns. Does the portfolio seem sensitive to movements in the S&P 500?\n",
    "4. An alternative way to calculate a rolling window is to take the exponentially weighted moving average. This is like a moving window average, but it assigns greater importance to more recent observations. Try calculating the ewm with a 21 day half-life."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and plot the rolling standard deviation for\n",
    "# the S&P 500 and whale portfolios using a 21 trading day window\n",
    "combined_df.rolling(window=21).std().plot(figsize=(20,10), title='21 day Rolling Standard Deviation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct a correlation table\n",
    "corr_df = combined_df.corr()\n",
    "corr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Beta for a single portfolio compared to the total market (S&P 500)\n",
    "# (Your graph may differ, dependent upon which portfolio you are comparing)\n",
    "\n",
    "#calcluating the rolling covariance using 60 day window:\n",
    "rolling_covariance = combined_df['BERKSHIRE HATHAWAY INC'].rolling(window=60).cov(combined_df['S&P 500'])\n",
    "\n",
    "# calcluating the variance of S&P 500 using 60 day window:\n",
    "rolling_variance = combined_df['S&P 500'].rolling(window=60).var()\n",
    "\n",
    "# calculating the beta of Berkshire Hathaway utilizing covariance and variance calculations above:\n",
    "rolling_BH_beta = rolling_covariance / rolling_variance\n",
    "\n",
    "# plotting the rolling 60-day Beta of Berkshire Hathaway relative to the S&P 500:\n",
    "rolling_BH_beta.plot(figsize=(20,10), title='Berksire Hathawway 60-day Rolling Beta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate a rolling window using the exponentially weighted moving average. \n",
    "ewm_df = combined_df.ewm(span=70).std()\n",
    "ewm_df.plot(figsize=(20,10), title='Exponentially Weighted Moving Average')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sharpe Ratios\n",
    "In reality, investment managers and thier institutional investors look at the ratio of return-to-risk, and not just returns alone. (After all, if you could invest in one of two portfolios, each offered the same 10% return, yet one offered lower risk, you'd take that one, right?)\n",
    "\n",
    "1. Using the daily returns, calculate and visualize the Sharpe ratios using a bar plot.\n",
    "2. Determine whether the algorithmic strategies outperform both the market (S&P 500) and the whales portfolios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate annualized Sharpe Ratios\n",
    "sharpe_df = (combined_df.mean() * 252) / (combined_df.std() * np.sqrt(252))\n",
    "sharpe_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the sharpe ratios as a bar plot\n",
    "sharpe_df.plot(kind='bar',title=\"Sharpe Ratios\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the basis of this performance metric, do our algo strategies outperform both 'the market' and the whales? Type your answer here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Portfolio Returns\n",
    "\n",
    "In this section, you will build your own portfolio of stocks, calculate the returns, and compare the results to the Whale Portfolios and the S&P 500. \n",
    "\n",
    "1. Visit [Google Sheets](https://docs.google.com/spreadsheets/) and use the in-built Google Finance function to choose 3-5 stocks for your own portfolio.\n",
    "2. Download the data as CSV files and calculate the portfolio returns.\n",
    "3. Calculate the returns for each stock.\n",
    "4. Using those returns, calculate the weighted returns for your entire portfolio assuming an equal number of shares for each stock.\n",
    "5. Add your portfolio returns to the DataFrame with the other portfolios and rerun the analysis. How does your portfolio fair?\n",
    "\n",
    "\n",
    "## Your analysis should include the following:\n",
    "\n",
    "- Using all portfolios:\n",
    " - The annualized standard deviation (252 trading days) for all portfolios.\n",
    " - The plotted rolling standard deviation using a 21 trading day window for all portfolios.\n",
    " - The calculated annualized Sharpe Ratios and the accompanying bar plot visualization.\n",
    " - A correlation table.\n",
    "- Using your custom portfolio and one other of your choosing:\n",
    " - The plotted beta. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose 3-5 custom stocks with at last 1 year's worth of historic prices and create a DataFrame of the closing prices and dates for each stock."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the first stock CSV, input into dataframe, sorted index, cleaned up index date format:\n",
    "cat_csv = Path('Resources/CAT_prices.csv')\n",
    "cat_df = pd.read_csv(cat_csv, index_col='Date', infer_datetime_format=True, parse_dates=True)\n",
    "cat_df.sort_index(inplace=True)\n",
    "cat_df.index = cat_df.index.date\n",
    "cat_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the second stock CSV, input into dataframe, sorted index, cleaned up index date format:\n",
    "cvs_csv = Path('Resources/CVS_prices.csv')\n",
    "cvs_df = pd.read_csv(cvs_csv, index_col='Date', infer_datetime_format=True, parse_dates=True)\n",
    "cvs_df.sort_index(inplace=True)\n",
    "cvs_df.index = cvs_df.index.date\n",
    "cvs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the third stock CSV, input into dataframe, sorted index, cleaned up index date format:\n",
    "pg_csv = Path('Resources/PG_prices.csv')\n",
    "pg_df = pd.read_csv(pg_csv, index_col='Date', infer_datetime_format=True, parse_dates=True)\n",
    "pg_df.sort_index(inplace=True)\n",
    "pg_df.index = pg_df.index.date\n",
    "pg_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the fourth stock CSV, input into dataframe, sorted index, cleaned up index date format:\n",
    "twtr_csv = Path('Resources/TWTR_prices.csv')\n",
    "twtr_df = pd.read_csv(twtr_csv, index_col='Date', infer_datetime_format=True, parse_dates=True)\n",
    "twtr_df.sort_index(inplace=True)\n",
    "twtr_df.index = twtr_df.index.date\n",
    "twtr_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the fifth stock CSV, input into dataframe, sorted index, cleaned up index date format:\n",
    "voo_csv = Path('Resources/VOO_prices.csv')\n",
    "voo_df = pd.read_csv(voo_csv, index_col='Date', infer_datetime_format=True, parse_dates=True)\n",
    "voo_df.sort_index(inplace=True)\n",
    "voo_df.index = voo_df.index.date\n",
    "voo_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all stocks into a single DataFrame and updated column headers:\n",
    "portfolio_df = pd.concat([cat_df, cvs_df, pg_df, twtr_df, voo_df], axis='columns', join='inner')\n",
    "portfolio_df.columns = [\"CAT\",'CVS','PG','TWTR','VOO']\n",
    "portfolio_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Nulls\n",
    "portfolio_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the weighted returns for the portfolio assuming an equal number of shares for each stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate weighted portfolio returns\n",
    "weights = [1/5, 1/5, 1/5, 1/5, 1/5]\n",
    "\n",
    "# calculating daily returns of portfolio and dropping null values:\n",
    "portfolio_returns = portfolio_df.pct_change().dropna()\n",
    "\n",
    "# calculating weighted returns:\n",
    "portfolio_returns_wt = portfolio_returns.dot(weights)\n",
    "portfolio_returns_wt.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join your portfolio returns to the DataFrame that contains all of the portfolio returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Add your \"Custom\" portfolio to the larger dataframe of fund returns\n",
    "all_df = pd.concat([combined_df, portfolio_returns_wt], axis='columns',join='inner')\n",
    "all_df.rename(columns={0 : 'Custom'}, inplace=True)\n",
    "all_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only compare dates where return data exists for all the stocks (drop NaNs)\n",
    "all_df.dropna(inplace=True)\n",
    "all_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-run the performance and risk analysis with your portfolio to see how it compares to the others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Risk\n",
    "all_df.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rolling Average:\n",
    "all_mean_df = all_df.rolling(window=180).mean()\n",
    "all_mean_df.plot(figsize=(20,10),title='180 Day Rolling Average')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rolling Standard Deviation:\n",
    "all_std_df = all_df.rolling(window=180).std()\n",
    "all_std_df.plot(figsize=(20,10),title='180 Day Rolling Standard Deviation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Annualized Sharpe Ratios\n",
    "sharpe_df = (all_df.mean() * 252) / (all_df.std() * np.sqrt(252))\n",
    "sharpe_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the sharpe ratios as a bar plot\n",
    "sharpe_df.plot(kind='bar', title='Sharpe Ratios')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a correlation analysis\n",
    "correlation = all_df.corr()\n",
    "correlation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a correlation heatmap\n",
    "sns.heatmap(correlation, vmin=-1, vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beta\n",
    "#calcluating the rolling covariance using 60 day window:\n",
    "rolling_covariance = all_df['Custom'].rolling(window=60).cov(all_df['S&P 500'])\n",
    "\n",
    "# calcluating the variance of S&P 500 using 60 day window:\n",
    "rolling_variance = all_df['S&P 500'].rolling(window=60).var()\n",
    "\n",
    "# calculating the beta of Custom Portfolio utilizing covariance and variance calculations above:\n",
    "rolling_custom_beta = rolling_covariance / rolling_variance\n",
    "\n",
    "# plotting the rolling 60-day Beta of Custom Portfolio:\n",
    "rolling_Custom_beta.plot(figsize=(20,10), title='Custom Portfolio 60-day Rolling Beta')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Portfolio Analysis Conslusion:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My custom portfolio is more risky than the overall market with a standard deviation of .010956 which is higher than the standard deviation of the S&P 500 over the same period (.008554) this is an indication that my custom portfolio is more volatile. Separately, my custom portfolio has a sharpe ratio of 0.309776 vs. the market which has a sharpe ratio of 0.648267 which indicates that my custom portfolio is not getting the best return relative to the risk of the portfolio. I would advise that this custom portfolio not be pursued as the historical returns have not outperformed S&P 500 for the risk that the custom portfolio holds. "
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
